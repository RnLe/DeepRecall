{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ca94d2e",
   "metadata": {},
   "source": [
    "# Step 1: Convert a Book to Markdown\n",
    "In this notebook, a book is converted to markdown format. The book can be in either PDF or EPUB format. The conversion is done using the custom `textProcessing` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16d606d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found input file: Eric-Jorgenson_The-Almanack-of-Naval-Ravikant_EBOOK_v103.epub\n",
      "Markdown version saved to: Eric-Jorgenson_The-Almanack-of-Naval-Ravikant_EBOOK_v103.md\n",
      "Cleaned markdown version saved to: Eric-Jorgenson_The-Almanack-of-Naval-Ravikant_EBOOK_v103_cleaned.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/renlephy/miniconda3/envs/python-api/lib/python3.12/site-packages/ebooklib/epub.py:1395: UserWarning: In the future version we will turn default option ignore_ncx to True.\n",
      "  warnings.warn('In the future version we will turn default option ignore_ncx to True.')\n",
      "/home/renlephy/miniconda3/envs/python-api/lib/python3.12/site-packages/ebooklib/epub.py:1423: FutureWarning: This search incorrectly ignores the root element, and will be fixed in a future version.  If you rely on the current behaviour, change it to './/xmlns:rootfile[@media-type]'\n",
      "  for root_file in tree.findall('//xmlns:rootfile[@media-type]', namespaces={'xmlns': NAMESPACES['CONTAINERNS']}):\n"
     ]
    }
   ],
   "source": [
    "# Import the custom module\n",
    "import os\n",
    "import textPreprocessing as tp\n",
    "\n",
    "input_file = 'Eric-Jorgenson_The-Almanack-of-Naval-Ravikant_EBOOK_v103.epub'\n",
    "output_markdown = input_file.replace('.epub', '.md')\n",
    "\n",
    "# Check if the input file exists\n",
    "if not os.path.exists(input_file):\n",
    "    print(f\"Input file {input_file} not found. Please check the path.\")\n",
    "else:\n",
    "    print(f\"Found input file: {input_file}\")\n",
    "\n",
    "converted_path = tp.convert_book_to_markdown(input_file, output_markdown)\n",
    "print(f\"Markdown version saved to: {converted_path}\")\n",
    "\n",
    "# Cleaning markdown text\n",
    "markdown = \"\"\n",
    "with open(output_markdown, 'r', encoding='utf-8') as file:\n",
    "    markdown = file.read()\n",
    "if not markdown:\n",
    "    print(\"Markdown file is empty. Please check the conversion process.\")\n",
    "\n",
    "cleaned_markdown = tp.clean_markdown_text(markdown)\n",
    "\n",
    "# Save the cleaned markdown text to a new file\n",
    "cleaned_markdown_path = converted_path.replace('.md', '_cleaned.md')\n",
    "with open(cleaned_markdown_path, 'w', encoding='utf-8') as file:\n",
    "    file.write(cleaned_markdown)\n",
    "print(f\"Cleaned markdown version saved to: {cleaned_markdown_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e77748c",
   "metadata": {},
   "source": [
    "# Step 2: Text Segmentation\n",
    "The text is then segmented into smaller parts for easier processing of the embeddings. The segmentation is done using the `textSegmentation` module. Two methods are provided for segmentation: \n",
    "1. **NLTK**: This method uses the Natural Language Toolkit (NLTK) for text segmentation.\n",
    "2. **LangChain**: This method uses the LangChain library for text segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c2ce30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using NLTK for text segmentation.\n",
      "NLTK TextTiling produced 374 segments.\n",
      "![cover.jpg](image/cover.jpg)\n",
      "\n",
      "![](image/1.png)\n",
      "\n",
      "Copyright © 2020 Eric Jorgenson\n",
      "\n",
      "All rights reserved.\n",
      "\n",
      "ISBN: 978-1-5445-1420-8\n",
      "\n",
      "This book has been created as a public service. It is available for free download in pdf and e-reader versions on [Navalmanack.com](https://Navalmanack.com). Naval is not earning any money on this book. Naval has essays, podcasts and more at [Nav.al](https://Nav.al) and is on Twitter @Naval.\n",
      "\n",
      "For my parents, who gave me everything and always seem to find a way to give  ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the segmentation functions from your module\n",
    "import textSegmentation as ts\n",
    "\n",
    "# Load your text from a file (e.g., your Markdown version of the book)\n",
    "def load_text(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return f.read()\n",
    "\n",
    "book_text = cleaned_markdown\n",
    "\n",
    "method = 'NLTK'\n",
    "# method = 'LangChain'\n",
    "\n",
    "segments = []\n",
    "\n",
    "if method == 'NLTK':\n",
    "    print(\"Using NLTK for text segmentation.\")\n",
    "\n",
    "    # Option 1: Segment using NLTK's TextTiling\n",
    "    segments = ts.segment_text_texttiling(book_text)\n",
    "    print(\"NLTK TextTiling produced\", len(segments), \"segments.\")\n",
    "\n",
    "if method == 'LangChain':\n",
    "    print(\"Using LangChain for text segmentation.\")\n",
    "    \n",
    "    # Option 2: Segment using LangChain's splitter\n",
    "    try:\n",
    "        segments = ts.segment_text_langchain(book_text, chunk_size=512, chunk_overlap=50)\n",
    "        print(\"LangChain splitter produced\", len(segments), \"chunks.\")\n",
    "    except ImportError as e:\n",
    "        print(\"LangChain not installed. Please install it via 'pip install langchain'.\")\n",
    "\n",
    "\n",
    "# Save the segments to a file\n",
    "ts.save_segments_to_file(segments, input_file.replace('.epub', '_segments.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343e7d43",
   "metadata": {},
   "source": [
    "# Step 3: Embedding Generation\n",
    "The segmented text is then converted into embeddings using the Sentence Transformers library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc1c9fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-08 21:04:54,573 - INFO - Use pytorch device_name: cuda:0\n",
      "2025-04-08 21:04:54,573 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5677ffaebd1540e78972b4b5b61f3d0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import logging\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Set logging to INFO level so that you can see more details in console output\n",
    "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(message)s', level=logging.INFO)\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "# Encode with the progress bar enabled\n",
    "embeddings = model.encode(segments, show_progress_bar=True, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18671a8",
   "metadata": {},
   "source": [
    "# Step 4: Post Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8edd91ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping of text segments to embeddings saved to: Eric-Jorgenson_The-Almanack-of-Naval-Ravikant_EBOOK_v103_mapped_embeddings.json\n"
     ]
    }
   ],
   "source": [
    "import textPostprocessing as tpost\n",
    "\n",
    "mappedEmbeddingOutput = input_file.replace('.epub', '_mapped_embeddings.json')\n",
    "tpost.map_text_to_embeddings(segments, embeddings, mappedEmbeddingOutput)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224fb1f5",
   "metadata": {},
   "source": [
    "# Step 5: Querying the Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7772003c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-08 22:29:01,818 - INFO - Use pytorch device_name: cuda:0\n",
      "2025-04-08 22:29:01,818 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fdfd92055f54a2c88538b7144ba6ea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment ID: 149\n",
      "Similarity: 0.6351\n",
      "Text snippet: Self-serving conclusions should have a higher bar.\n",
      "\n",
      "I do view a lot of my goals over the next few years of unconditioning previous learned responses or habituated responses, so I can make decisions more cleanly in the moment without relying on memory or prepackaged heuristics and judgments. [4]\n",
      "\n",
      "Almost all biases are time-saving heuristics. For important decisions, discard memory and identity, and focus on the problem. ...\n",
      "--------------------------------------------------------------------------------\n",
      "Segment ID: 264\n",
      "Similarity: 0.5429\n",
      "Text snippet: If I saw a guy with a bad hair day, I would at first think “Haha, he has a bad hair day.” Well, why am I laughing at him to make me feel better about myself? And why am I trying to make me feel better about my own hair? Because I’m losing my hair, and I’m afraid it’s going to go away. What I find is 90 percent of thoughts I have are fear-based. The other 10 percent may be desire- based.\n",
      "\n",
      "You don’t make any decisions. You don’t judge anything. You just accept everything. If I do that for ten or fifteen minutes while walking around, I end up in a very peaceful, grateful state. Choiceless Awareness works well for me. [6] ...\n",
      "--------------------------------------------------------------------------------\n",
      "Segment ID: 135\n",
      "Similarity: 0.5200\n",
      "Text snippet: Judgment. Judgment is underrated. [1]\n",
      "\n",
      "Can you define judgment?\n",
      "\n",
      "My definition of wisdom is knowing the long-term consequences of your actions. Wisdom applied to external problems is judgment. They’re highly linked; knowing the long-term consequences of your actions and then making the right decision to capitalize on that. [78]\n",
      "\n",
      "In an age of leverage, one correct decision can win everything.\n",
      "\n",
      "Without hard work, you’ll develop neither judgment nor leverage.\n",
      "\n",
      "You have to put in the time, but the judgment is more important. The direction you’re heading in matters more than how fast you move, especially with leverage. Picking the direction you’re heading in for every decision is far, far more important than how much force you apply. Just pick the right direction to start walking in, and start walking. [1] ...\n",
      "--------------------------------------------------------------------------------\n",
      "Segment ID: 245\n",
      "Similarity: 0.5076\n",
      "Text snippet: The combinatorics of human DNA and experience are staggering. You will never meet any two humans who are substitutable for each other.\n",
      "\n",
      "Your goal in life is to find the people, business, project, or art that needs you the most. There is something out there just for you. What you don’t want to do is build checklists and decision frameworks built on what other people are doing. You’re never going to be them. You’ll never be good at being somebody else. [4]\n",
      "\n",
      "To make an original contribution, you have to be irrationally obsessed with something.\n",
      "\n",
      "# Choosing to Care for Yourself ...\n",
      "--------------------------------------------------------------------------------\n",
      "Segment ID: 90\n",
      "Similarity: 0.5056\n",
      "Text snippet: ![](image/earn_mind.png)\n",
      "\n",
      "# Get Paid for Your Judgment\n",
      "\n",
      "Choosing what kinds of jobs, careers, or fields you get into and what sort of deals you’re willing to take from your employer will give you much more free time. Then, you don’t have to worry as much about time management. I would love to be paid purely for my judgment, not for any work. I want a robot, capital, or computer to do the work, but I want to be paid for my judgment. [1]\n",
      "\n",
      "I think every human should aspire to being knowledgeable about certain things and being paid for our unique knowledge. We have as much leverage as is possible in our business, whether it’s through robots or computers or what have you. Then, we can be masters of our own time because we are just being tracked on outputs and not inputs.\n",
      "\n",
      "Imagine someone comes along who demonstrably has slightly better judgment. They’re right 85 percent of the time instead of 75 percent. You will pay them $50 million, $100 million, $200 million, whatever it takes, because 10 percent better judgment steering a $100 billion ship is very valuable. CEOs are highly paid because of their leverage. Small differences in judgment and capability really get amplified. [2] ...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import textQuerying as tq\n",
    "\n",
    "# Specify the path to your mapped embedding file.\n",
    "mapping_file = mappedEmbeddingOutput\n",
    "\n",
    "# Define a query string.\n",
    "query = \"The importance of self-awareness in decision-making.\"\n",
    "\n",
    "# Load your SentenceTransformer model (should be the same model used in step 3).\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "# Retrieve the top 5 matching segments.\n",
    "top_matches = tq.query_mapped_embeddings(query, mapping_file, model, top_k=5)\n",
    "\n",
    "# Print out the top matching segments\n",
    "for match in top_matches:\n",
    "    print(f\"Segment ID: {match['id']}\")\n",
    "    print(f\"Similarity: {match['similarity']:.4f}\")\n",
    "    print(\"Text snippet:\", match['text'], \"...\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5b759b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-api",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
